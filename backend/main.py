import logging
import os
import time
import datetime
import uuid
from contextlib import asynccontextmanager
from typing import Optional, List, Dict, Any

from fastapi import FastAPI, Depends, HTTPException, Request, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.responses import JSONResponse
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field, ConfigDict
import structlog
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.asyncio import AsyncioIntegration

# Importa√ß√µes internas protegidas
try:
    from app.core.llm_orchestrator import LLMOrchestrator
    from app.models.local_llm import OllamaLLM
    from app.models.api_llm import OpenRouterLLM, CohereLLM
    from app.core.config import settings
    from app.core.rate_limiter import RateLimiter
    from app.core.metrics import metrics_middleware
    # ‚úÖ CORRE√á√ÉO: Importar exce√ß√µes do m√≥dulo separado
    from app.core.exceptions import (
        LLMServiceError, 
        OrchestrationError, 
        RateLimitError,
        APIKeyError,
        ServiceUnavailableError
    )
except ImportError as e:
    print(f"‚ùå Erro ao importar depend√™ncias: {e}")
    raise

# --- Configura√ß√£o de Logging Estruturado ---
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# --- Configura√ß√£o Sentry para Monitoramento ---
if hasattr(settings, 'SENTRY_DSN') and settings.SENTRY_DSN:
    sentry_sdk.init(
        dsn=settings.SENTRY_DSN,
        integrations=[
            FastApiIntegration(auto_enable=True),
            AsyncioIntegration(),
        ],
        traces_sample_rate=0.1,
        environment=getattr(settings, 'ENVIRONMENT', 'development'),
        release=getattr(settings, 'VERSION', 'unknown'),
    )
    logger.info("‚úÖ Sentry configurado com sucesso")

# --- Inst√¢ncias de Seguran√ßa e Utilit√°rios ---
security = HTTPBearer()
rate_limiter = RateLimiter()

# ‚ùå REMOVIDO: Exce√ß√µes customizadas movidas para app/core/exceptions.py

# --- Gerenciamento do Ciclo de Vida da Aplica√ß√£o ---
@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    ‚úÖ CORRE√á√ÉO: Fun√ß√£o lifespan completamente implementada
    Gerencia o ciclo de vida da aplica√ß√£o FastAPI.
    """
    logger.info("üöÄ Iniciando Muzaia Legal Assistant API")  # ‚úÖ CORRE√á√ÉO: Nome corrigido
    
    # Inicializa√ß√£o
    try:
        # Inicializar modelos LLM
        ollama_llm = OllamaLLM()
        openrouter_llm = OpenRouterLLM()
        cohere_llm = CohereLLM()
        
        # Inicializar orquestrador
        orchestrator = LLMOrchestrator(
            models=[ollama_llm, openrouter_llm, cohere_llm]
        )
        
        # Armazenar no estado da aplica√ß√£o
        app.state.orchestrator = orchestrator
        app.state.requests_total = 0
        app.state.avg_response_time = 0
        app.state.active_connections = 0
        app.state.startup_time = datetime.datetime.utcnow()
        
        logger.info("‚úÖ Orquestrador LLM inicializado com sucesso")
        
        yield
        
    except Exception as e:
        logger.error("‚ùå Erro durante inicializa√ß√£o", error=str(e), exc_info=True)
        raise ServiceUnavailableError(f"Falha na inicializa√ß√£o: {str(e)}")
    finally:
        # ‚úÖ CORRE√á√ÉO: Cleanup implementado
        logger.info("üîÑ Encerrando Muzaia Legal Assistant API")
        if hasattr(app.state, 'orchestrator'):
            try:
                await app.state.orchestrator.cleanup()
                logger.info("‚úÖ Cleanup do orquestrador realizado")
            except Exception as e:
                logger.error("‚ùå Erro durante cleanup", error=str(e))

# --- Cria√ß√£o da Aplica√ß√£o FastAPI ---
app = FastAPI(
    title="Muzaia Legal Assistant API",  # ‚úÖ CORRE√á√ÉO: Nome corrigido
    description="Plataforma Jur√≠dica Aut√¥noma para Mo√ßambique com IA Multi-Modal",
    version="1.0.0",
    docs_url="/docs" if getattr(settings, 'ENVIRONMENT', 'production') == "development" else None,
    redoc_url="/redoc" if getattr(settings, 'ENVIRONMENT', 'production') == "development" else None,
    openapi_url="/openapi.json",
    lifespan=lifespan  # ‚úÖ CORRE√á√ÉO: Lifespan implementado
)

# --- Middlewares ---
# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=getattr(settings, 'ALLOWED_ORIGINS', ["*"]),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Trusted Host (Seguran√ßa)
if hasattr(settings, 'ALLOWED_HOSTS'):
    app.add_middleware(
        TrustedHostMiddleware,
        allowed_hosts=settings.ALLOWED_HOSTS
    )

# ‚úÖ CORRE√á√ÉO: Middleware de m√©tricas
app.add_middleware(metrics_middleware)

# --- Modelos Pydantic ---
class ChatRequest(BaseModel):
    model_config = ConfigDict(str_strip_whitespace=True)

    message: str = Field(
        ...,
        min_length=1,
        max_length=2000,
        description="A pergunta jur√≠dica para a IA.",
        example="Quais s√£o os requisitos legais para o registro de uma empresa em Mo√ßambique?"
    )
    context: Optional[str] = Field(
        "general",
        description="Contexto legal espec√≠fico para orientar a resposta da IA.",
        example="direitoempresarial"
    )
    min_confidence: Optional[float] = Field(
        75.0,
        ge=0.0,
        le=100.0,
        description="Pontua√ß√£o de confian√ßa m√≠nima (0-100) exigida para a resposta da IA.",
        example=85.0
    )
    user_id: Optional[str] = Field(
        None,
        description="Identificador √∫nico do usu√°rio que faz a requisi√ß√£o.",
        example="user_12345"
    )
    conversation_id: Optional[str] = Field(
        None,
        description="Identificador √∫nico da conversa.",
        example="conv_abcde"
    )
    priority: Optional[str] = Field(
        "normal",
        pattern="^(low|normal|high|urgent)$",
        description="Prioridade da requisi√ß√£o.",
        example="high"
    )

class ChatResponse(BaseModel):
    response: str = Field(..., description="A resposta jur√≠dica gerada pela IA.")
    confidence_score: float = Field(..., ge=0.0, le=100.0, description="Pontua√ß√£o de confian√ßa (0-100).")
    models_used: List[str] = Field(..., description="Lista dos modelos de IA utilizados.")
    requires_human_review: bool = Field(..., description="Indica se requer revis√£o humana.")
    sources: List[str] = Field(default_factory=list, description="Lista de fontes legais consultadas.")
    context: str = Field(..., description="O contexto legal aplicado na consulta.")
    conversation_id: Optional[str] = Field(None, description="ID da conversa.")
    response_time_ms: Optional[float] = Field(None, description="Tempo de resposta em milissegundos.")
    disclaimer: str = Field(
        default="Esta resposta √© gerada por IA e deve ser verificada por um profissional jur√≠dico qualificado.",
        description="Aviso legal padr√£o."
    )

class HealthResponse(BaseModel):
    status: str = Field(..., description="Status geral da aplica√ß√£o.")
    version: str = Field(..., description="Vers√£o atual da API.")
    timestamp: str = Field(..., description="Timestamp da verifica√ß√£o no formato ISO 8601.")
    services: Dict[str, str] = Field(..., description="Status individual dos servi√ßos internos.")

# --- Depend√™ncias ---
def get_orchestrator() -> LLMOrchestrator:
    """‚úÖ CORRE√á√ÉO: Valida√ß√£o robusta do orquestrador"""
    if not hasattr(app.state, 'orchestrator'):
        logger.error("‚ùå Orquestrador n√£o inicializado")
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Servi√ßo n√£o est√° pronto. Tente novamente em alguns instantes."
        )
    return app.state.orchestrator

async def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)) -> str:
    """‚úÖ CORRE√á√ÉO: Verifica√ß√£o melhorada da API key"""
    api_key = credentials.credentials
    
    if not hasattr(settings, 'API_KEYS') or not settings.API_KEYS:
        logger.warning("‚ö†Ô∏è Nenhuma API key configurada")
        raise APIKeyError("Configura√ß√£o de API key n√£o encontrada")
    
    if api_key not in settings.API_KEYS:
        logger.warning("üîê Tentativa de acesso com API key inv√°lida", api_key_prefix=api_key[:8])
        raise APIKeyError("API key inv√°lida")
    
    return api_key

async def check_rate_limit(request: Request):
    """‚úÖ CORRE√á√ÉO: Rate limiting implementado"""
    try:
        await rate_limiter.check_rate_limit(
            key=request.client.host,
            limit=100,  # 100 requests
            window=3600  # por hora
        )
    except RateLimitError:
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            content={"detail": "Limite de taxa excedido. Tente novamente mais tarde."}
        )

# --- Middleware de Request ID ---
@app.middleware("http")
async def add_request_id(request: Request, call_next):
    """‚úÖ CORRE√á√ÉO: Middleware de request tracking"""
    request_id = str(uuid.uuid4())
    request.state.request_id = request_id
    
    with structlog.contextvars.bound_contextvars(request_id=request_id):
        response = await call_next(request)
        response.headers["X-Request-ID"] = request_id
        return response

# --- Endpoints ---
@app.get("/", response_model=Dict[str, Any], summary="Informa√ß√µes da API")
async def root():
    """Retorna informa√ß√µes b√°sicas sobre a API Muzaia Legal Assistant."""  # ‚úÖ CORRE√á√ÉO: Nome corrigido
    return {
        "message": "Muzaia Legal Assistant API",  # ‚úÖ CORRE√á√ÉO: Nome corrigido
        "version": "1.0.0",
        "status": "active",
        "description": "Plataforma Jur√≠dica Aut√¥noma para Mo√ßambique com IA Multi-Modal.",
        "docs_url": "/docs" if getattr(settings, 'ENVIRONMENT', 'production') == "development" else "Dispon√≠vel apenas em ambiente de desenvolvimento."
    }

@app.get("/health", response_model=HealthResponse, summary="Verifica√ß√£o de Sa√∫de da Aplica√ß√£o")
async def health_check():
    """‚úÖ CORRE√á√ÉO: Health check melhorado"""
    services_status = {}
    
    # Verificar orquestrador
    try:
        if hasattr(app.state, 'orchestrator') and app.state.orchestrator:
            services_status["orchestrator"] = "healthy"
        else:
            services_status["orchestrator"] = "unhealthy"
    except Exception:
        services_status["orchestrator"] = "unhealthy"
    
    # Status geral
    overall_status = "healthy" if all(status == "healthy" for status in services_status.values()) else "degraded"
    
    return HealthResponse(
        status=overall_status,
        version="1.0.0",
        timestamp=datetime.datetime.now(datetime.timezone.utc).isoformat(),
        services=services_status
    )

@app.post("/chat", response_model=ChatResponse, summary="Consulta Jur√≠dica com IA")
async def legal_chat(
    request: ChatRequest,
    orchestrator: LLMOrchestrator = Depends(get_orchestrator),
    api_key: str = Depends(verify_api_key),
    _: None = Depends(check_rate_limit)
):
    """‚úÖ CORRE√á√ÉO: Endpoint melhorado com tratamento robusto"""
    start_time = time.time()
    
    logger.info(
        "üìù Nova consulta jur√≠dica recebida",
        user_id=request.user_id,
        conversation_id=request.conversation_id,
        query_length=len(request.message)
    )
    
    try:
        # Processar consulta
        result = await orchestrator.get_legal_response(
            query=request.message,
            context=request.context,
            min_confidence=request.min_confidence,
            user_id=request.user_id,
            conversation_id=request.conversation_id
        )
        
        response_time_ms = (time.time() - start_time) * 1000
        
        # ‚úÖ CORRE√á√ÉO: Incrementar m√©tricas
        if hasattr(app.state, 'requests_total'):
            app.state.requests_total += 1
        
        logger.info(
            "‚úÖ Consulta processada com sucesso",
            user_id=request.user_id,
            confidence_score=result.get("confidence_score", 0),
            response_time_ms=response_time_ms,
            models_used=result.get("models_used", [])
        )
        
        return ChatResponse(
            response=result.get("text", ""),
            confidence_score=result.get("confidence_score", 0),
            models_used=result.get("models_used", []),
            requires_human_review=result.get("requires_human_review", False),
            sources=result.get("sources", []),
            context=result.get("context", request.context),
            conversation_id=result.get("conversation_id"),
            response_time_ms=response_time_ms
        )
        
    except (LLMServiceError, OrchestrationError) as e:
        logger.error(
            "‚ùå Erro espec√≠fico no orquestrador/LLM",
            error=str(e),
            code=getattr(e, 'code', 'UNKNOWN'),
            user_id=request.user_id,
            exc_info=True
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erro ao processar consulta jur√≠dica: {e.message}"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(
            "‚ùå Erro inesperado durante consulta jur√≠dica",
            error=str(e),
            user_id=request.user_id,
            exc_info=True
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Erro interno ao processar sua solicita√ß√£o. Tente novamente mais tarde."
        )

@app.get("/metrics", summary="M√©tricas de Desempenho da API")
async def metrics(api_key: str = Depends(verify_api_key)):
    """‚úÖ CORRE√á√ÉO: M√©tricas melhoradas"""
    return {
        "requests_total": getattr(app.state, "requests_total", 0),
        "average_response_time_ms": getattr(app.state, "avg_response_time", 0),
        "active_connections": getattr(app.state, "active_connections", 0),
        "uptime_seconds": (datetime.datetime.utcnow() - getattr(app.state, "startup_time", datetime.datetime.utcnow())).total_seconds(),
        "timestamp": datetime.datetime.utcnow().isoformat()
    }

# --- Execu√ß√£o da Aplica√ß√£o ---
if __name__ == "__main__":
    import uvicorn
    
    # ‚úÖ CORRE√á√ÉO: Configura√ß√£o melhorada do uvicorn
    uvicorn_config = {
        "app": "main:app",
        "host": "0.0.0.0",
        "port": 8000,
        "reload": getattr(settings, 'ENVIRONMENT', 'production') == "development",
        "workers": 1 if getattr(settings, 'ENVIRONMENT', 'production') == "development" else (os.cpu_count() or 1) * 2,
        "log_config": None,  # ‚úÖ CORRE√á√ÉO: Usar structlog
        "access_log": False,  # ‚úÖ CORRE√á√ÉO: Desabilitar logs de acesso padr√£o
    }
    
    logger.info("üöÄ Iniciando servidor Muzaia", config=uvicorn_config)  # ‚úÖ CORRE√á√ÉO: Nome corrigido
    uvicorn.run(**uvicorn_config)
